{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルが全て同じものを返さないかをみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../data/data/train_fish/\"\n",
    "# path devided into kinds of image\n",
    "ALB = \"ALB\"\n",
    "BET = \"BET\"\n",
    "DOL = \"DOL\"\n",
    "LAG = \"LAG\"\n",
    "NoF = \"NoF\"\n",
    "OTHER = \"OTHER\"\n",
    "SHARK = \"SHARK\"\n",
    "YFT = \"YFT\"\n",
    "FISH_CLASSES = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n",
    "IMAGE_SIZE = 32\n",
    "channnels=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def accuracy(logits,labels):\n",
    "    correct_prediction = tf.equal(tf.argmax(logits,1),tf.argmax(labels,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,\"float\"))\n",
    "    return accuracy\n",
    "def split_image_and_label(data_list,LESS=False):\n",
    "    '''\n",
    "    data_list should be [[data,label]...]\n",
    "    '''\n",
    "    data = []\n",
    "    labels = []\n",
    "    if LESS:\n",
    "        i=0\n",
    "        for value,label in data_list:\n",
    "            i+=1\n",
    "            data.append(value)\n",
    "            labels.append(label)\n",
    "            if i == 1000:\n",
    "                break\n",
    "        return data,labels\n",
    "    else:\n",
    "        for value,label in data_list:\n",
    "            data.append(value)\n",
    "            labels.append(label)\n",
    "        return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file load\n",
    "def load_files(path):\n",
    "    data = []\n",
    "    save_pa = []\n",
    "    for pa,_,_ in os.walk(path):\n",
    "        if pa =='../data/data/train_fish/':\n",
    "            continue\n",
    "        save_pa.append(pa)\n",
    "    for i_c, cat in enumerate(save_pa):\n",
    "        for _,_,files in os.walk(cat):\n",
    "            for file in files:\n",
    "                label = np.zeros(8)\n",
    "                label[i_c] = 1\n",
    "                filepath = os.path.join(cat,file)\n",
    "                data.append([filepath,label])\n",
    "    return data\n",
    "DATA = load_files(PATH)\n",
    "import csv\n",
    "with open(\"../data/meta.csv\",'w') as f:\n",
    "    writer = csv.writer(f,lineterminator='\\n')\n",
    "    writer.writerow(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データロード\n",
    "# DATA = [(d[1],d[0]) for d in DATA]\n",
    "import random\n",
    "random.shuffle(DATA)\n",
    "num_train = int(len(DATA) * 0.8)\n",
    "train = DATA[:num_train]\n",
    "test = DATA[num_train:]\n",
    "\n",
    "#trainデータを三倍にかさ増しする。\n",
    "train = train*3\n",
    "test_image,test_label = split_image_and_label(test,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(image):\n",
    "    image = image.flatten().astype(np.float32)/255.0\n",
    "    return image\n",
    "# opnecvによる読み込み\n",
    "import cv2 \n",
    "def convert_image_path_to_data_cv2(path,i):\n",
    "    try:\n",
    "#         img2 = cv2.imread(path,0) # 白黒画像で読み込み\n",
    "        img2 = cv2.imread(path)\n",
    "\n",
    "        img2 = cv2.resize(img2,dsize=(IMAGE_SIZE,IMAGE_SIZE),interpolation = cv2.INTER_CUBIC)\n",
    "        np_image_data = np.asarray(img2)\n",
    "        np_final = np.expand_dims(np_image_data,axis=0)\n",
    "        np_final = flatten(np_final)\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "        #1000 images / 15s\n",
    "        return np_final\n",
    "    except:\n",
    "        print(path)\n",
    "        print(i)\n",
    "        return np.zeros([IMAGE_SIZE,IMAGE_SIZE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# これらコードは、http://kivantium.hateblo.jp/entry/2015/11/18/233834から得られる\n",
    "def inference(images_placeholder,keep_prob):\n",
    "    def weight_variable(shape):\n",
    "        initial = tf.truncated_normal(shape,stddev=0.1)\n",
    "        return tf.Variable(initial)\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.constant(0.1,shape=shape)\n",
    "        return tf.Variable(initial)\n",
    "    def conv2d(x,W):\n",
    "        return tf.nn.conv2d(x,W,[1,1,1,1],padding='SAME')\n",
    "    def max_pool_2x2(x):\n",
    "        return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "\n",
    "#     x_image = tf.reshape(images_placeholder,[-1,256,256,3])\n",
    "    x_image = tf.reshape(images_placeholder,[-1,IMAGE_SIZE,IMAGE_SIZE,3])\n",
    "    #  32 * 32 * 3 tensorへ変換する\n",
    "\n",
    "    with tf.name_scope('conv1') as scope:\n",
    "        W_conv1 = weight_variable([5,5,3,32])\n",
    "        b_conv1 = bias_variable([32])\n",
    "        h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1) + b_conv1)\n",
    "\n",
    "    with tf.name_scope('pool1') as scope:\n",
    "        h_pool1 = max_pool_2x2(h_conv1)\n",
    "        \n",
    "    with tf.name_scope('conv2') as scope:\n",
    "        W_conv2 = weight_variable([5,5,32,64])\n",
    "        b_conv2 = bias_variable([64])\n",
    "        h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2) + b_conv2)\n",
    "        \n",
    "    with tf.name_scope('pool2') as scope:\n",
    "        h_pool2 = max_pool_2x2(h_conv2)\n",
    "        # h_pool2 has (?, 64, 64, 64) shape\n",
    "    #全結合\n",
    "    with tf.name_scope('zenketsu1') as scope:\n",
    "#         W_fc1 = weight_variable([64*64*64,1024])\n",
    "        W_fc1 = weight_variable([64*64*1,1024])\n",
    "        b_fc1 = bias_variable([1024])\n",
    "#         h_pool2_flat = tf.reshape(h_pool2,[-1,64*64*64]) #3136 defined here\n",
    "        h_pool2_flat = tf.reshape(h_pool2,[-1,64*64*1]) #3136 defined here\n",
    "        \n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1) + b_fc1)\n",
    "        #dropout\n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)\n",
    "        \n",
    "    with tf.name_scope('zenketsu2') as scope:\n",
    "        W_fc2 = weight_variable([1024,NUM_CLASSES])\n",
    "        b_fc2 = bias_variable([NUM_CLASSES])\n",
    "    \n",
    "    with tf.name_scope('softmax') as scope:\n",
    "        y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2) + b_fc2)\n",
    "    \n",
    "    return y_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALB  BET  DOL  LAG  NoF  OTHER\tSHARK  YFT\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../data/data/train_fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "test_image,test_label = split_image_and_label(test,False) \n",
    "test_image = [convert_image_path_to_data_cv2(path,i) for i,path in enumerate(test_image)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10196079, 0.1254902 , 0.13725491, ..., 0.6313726 , 0.5647059 ,\n",
       "       0.5372549 ], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../data/model/model.ckpt\n",
      "restored\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Fetch argument 'softmax_Softmax' cannot be interpreted as a Tensor. (\"The name 'softmax_Softmax' refers to an Operation not in the graph.\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/yes/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    299\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 300\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    301\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3489\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3490\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3549\u001b[0m           raise KeyError(\"The name %s refers to an Operation not in the \"\n\u001b[0;32m-> 3550\u001b[0;31m                          \"graph.\" % repr(name))\n\u001b[0m\u001b[1;32m   3551\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"The name 'softmax_Softmax' refers to an Operation not in the graph.\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-db4eeb981770>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"restored\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'softmax_Softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_operations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1137\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \"\"\"\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' % (fetch,\n",
      "\u001b[0;32m~/yes/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    308\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n\u001b[0;32m--> 310\u001b[0;31m                          'Tensor. (%s)' % (fetch, str(e)))\n\u001b[0m\u001b[1;32m    311\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_contraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Fetch argument 'softmax_Softmax' cannot be interpreted as a Tensor. (\"The name 'softmax_Softmax' refers to an Operation not in the graph.\")"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    with tf.Session() as sess:\n",
    "        t_input = tf.placeholder(np.float32,name='input')\n",
    "        saver = tf.train.import_meta_graph('../data/model/model.ckpt.meta',{'input':t_input})\n",
    "        saved_path = '../data/model/model.ckpt'\n",
    "        saver.restore(sess,saved_path)\n",
    "        print(\"restored\")\n",
    "        graph = tf.get_default_graph()\n",
    "        print(sess.run(tf.get_operations()'softmax_Softmax'))\n",
    "        print(graph.get_operations())\n",
    "\n",
    "        \n",
    "#         print(sess.run(tf.get_collection(tf.GraphKeys.VARIABLES)))\n",
    "\n",
    "#         print(sess.run([n.name for n in tf.get_default_graph().as_graph_def().node]))\n",
    "#         print(sess.run(inference,feed_dict={\n",
    "#             inputs: test_image\n",
    "#         }))\n",
    "        #test結果の答えと実際の値を見る\n",
    "        # test_imageは実際にデータを取っている。\n",
    "        for i,val in enumerate(test_image):\n",
    "            result = inference(val,1.0)\n",
    "            print(result)\n",
    "            print(test_label[i])\n",
    "            if i == 100:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Graph().as_default():\n",
    "    with tf.Session() as sess:\n",
    "        saver = tf.train.import_meta_graph('../data/model/model.ckpt.meta')\n",
    "        saved_path = '../data/model/model.ckpt'\n",
    "        saver.restore(sess,saved_path)\n",
    "        print(\"restored\")\n",
    "\n",
    "        print(sess.run('gradients/softmax/MatMul_grad/tuple/control_dependency_1' , feed_dict={\n",
    "            \"Placeholder_1\": test_image\n",
    "        }))\n",
    "#         print(sess.run(tf.get_collection(tf.GraphKeys.VARIABLES)))\n",
    "\n",
    "#         print(sess.run([n.name for n in tf.get_default_graph().as_graph_def().node]))\n",
    "#         print(sess.run(inference,feed_dict={\n",
    "#             inputs: test_image\n",
    "#         }))\n",
    "        #test結果の答えと実際の値を見る\n",
    "        # test_imageは実際にデータを取っている。\n",
    "        for i,val in enumerate(test_image):\n",
    "            result = inference(val,1.0)\n",
    "            print(result)\n",
    "            print(test_label[i])\n",
    "            if i == 100:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
