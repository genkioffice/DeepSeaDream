{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../data/data/train_fish/\"\n",
    "# path devided into kinds of image\n",
    "ALB = \"ALB\"\n",
    "BET = \"BET\"\n",
    "DOL = \"DOL\"\n",
    "LAG = \"LAG\"\n",
    "NoF = \"NoF\"\n",
    "OTHER = \"OTHER\"\n",
    "SHARK = \"SHARK\"\n",
    "YFT = \"YFT\"\n",
    "FISH_CLASSES = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n",
    "channnels=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データはディレクトリごとに別れていて、合計で3777枚ある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for path, di, file  in os.walk(PATH):\n",
    "    CLASS = di\n",
    "    break\n",
    "NUM_CLASSES = len(CLASS)\n",
    "# IMAGE_SIZE = 256\n",
    "IMAGE_SIZE = 32\n",
    "IMAGE_PIXELS = IMAGE_SIZE*IMAGE_SIZE*3\n",
    "\n",
    "\n",
    "learning_rate = 1e-4\n",
    "max_steps = 120\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# これらコードは、http://kivantium.hateblo.jp/entry/2015/11/18/233834から得られる\n",
    "def inference(images_placeholder,keep_prob):\n",
    "    def weight_variable(shape):\n",
    "        initial = tf.truncated_normal(shape,stddev=0.1)\n",
    "        return tf.Variable(initial)\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.constant(0.1,shape=shape)\n",
    "        return tf.Variable(initial)\n",
    "    def conv2d(x,W):\n",
    "        return tf.nn.conv2d(x,W,[1,1,1,1],padding='SAME')\n",
    "    def max_pool_2x2(x):\n",
    "        return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "\n",
    "#     x_image = tf.reshape(images_placeholder,[-1,256,256,3])\n",
    "    x_image = tf.reshape(images_placeholder,[-1,IMAGE_SIZE,IMAGE_SIZE,3])\n",
    "    #  32 * 32 * 3 tensorへ変換する\n",
    "\n",
    "    with tf.name_scope('conv1') as scope:\n",
    "        W_conv1 = weight_variable([5,5,3,32])\n",
    "        b_conv1 = bias_variable([32])\n",
    "        h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1) + b_conv1)\n",
    "\n",
    "    with tf.name_scope('pool1') as scope:\n",
    "        h_pool1 = max_pool_2x2(h_conv1)\n",
    "        \n",
    "    with tf.name_scope('conv2') as scope:\n",
    "        W_conv2 = weight_variable([5,5,32,64])\n",
    "        b_conv2 = bias_variable([64])\n",
    "        h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2) + b_conv2)\n",
    "        \n",
    "    with tf.name_scope('pool2') as scope:\n",
    "        h_pool2 = max_pool_2x2(h_conv2)\n",
    "        # h_pool2 has (?, 64, 64, 64) shape\n",
    "    #全結合\n",
    "    with tf.name_scope('zenketsu1') as scope:\n",
    "#         W_fc1 = weight_variable([64*64*64,1024])\n",
    "        W_fc1 = weight_variable([64*64*1,1024])\n",
    "        b_fc1 = bias_variable([1024])\n",
    "#         h_pool2_flat = tf.reshape(h_pool2,[-1,64*64*64]) #3136 defined here\n",
    "        h_pool2_flat = tf.reshape(h_pool2,[-1,64*64*1]) #3136 defined here\n",
    "        \n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1) + b_fc1)\n",
    "        #dropout\n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)\n",
    "        \n",
    "    with tf.name_scope('zenketsu2') as scope:\n",
    "        W_fc2 = weight_variable([1024,NUM_CLASSES])\n",
    "        b_fc2 = bias_variable([NUM_CLASSES])\n",
    "    \n",
    "    with tf.name_scope('softmax') as scope:\n",
    "        y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2) + b_fc2)\n",
    "    \n",
    "    return y_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(logits,labels):\n",
    "    cross_entropy = -tf.reduce_sum(labels*tf.log(logits))\n",
    "#     tf.scalar_summary(\"cross_entropy\",cross_entropy)\n",
    "    return cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(loss,learning_rate):\n",
    "    train_step = tf.train.AdadeltaOptimizer(learning_rate).minimize(loss)\n",
    "    return train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file load\n",
    "def load_files(path):\n",
    "    data = []\n",
    "    save_pa = []\n",
    "    for pa,_,_ in os.walk(path):\n",
    "        if pa =='../data/data/train_fish/':\n",
    "            continue\n",
    "        save_pa.append(pa)\n",
    "    for i_c, cat in enumerate(save_pa):\n",
    "        for _,_,files in os.walk(cat):\n",
    "            for file in files:\n",
    "                label = np.zeros(8)\n",
    "                label[i_c] = 1\n",
    "                filepath = os.path.join(cat,file)\n",
    "                data.append([filepath,label])\n",
    "    return data\n",
    "DATA = load_files(PATH)\n",
    "import csv\n",
    "with open(\"../data/meta.csv\",'w') as f:\n",
    "    writer = csv.writer(f,lineterminator='\\n')\n",
    "    writer.writerow(DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用しているデータの頻度を掛けないといけないかも。それ以外の解放だと、入れたデータについて、albが出る確率が0.5以上であるかどうか。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/data/train_fish/NoF/img_04395.jpg',\n",
       " array([1., 0., 0., 0., 0., 0., 0., 0.])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3777"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA = [(d[1],d[0]) for d in DATA]\n",
    "import random\n",
    "random.shuffle(DATA)\n",
    "num_train = int(len(DATA) * 0.8)\n",
    "train = DATA[:num_train]\n",
    "test = DATA[num_train:]\n",
    "\n",
    "#trainデータを三倍にかさ増しする。\n",
    "train = train*3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "精度が0.11で固定されていたので、学習量不足と判断し、データ数を増やした。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_batch(data_list):\n",
    "#     labels,paths = [],[]\n",
    "#     for data in data_list:\n",
    "#         labels.append(data[0])\n",
    "#         paths.append(data[1])\n",
    "#     queue = tf.train.slice_input_producer([labels,paths])\n",
    "#     label = queue[0]\n",
    "\n",
    "\n",
    "#     jpeg = tf.read_file(queue[1])\n",
    "#     image = tf.image.decode_jpeg(jpeg,channels=3)\n",
    "#     image = tf.image.resize_images(image,[256,256])\n",
    "\n",
    "#     image = tf.image.per_image_standardization(image)\n",
    "\n",
    "#     return tf.train.shuffle_batch([image,label],batch_size=32,\n",
    "#                                   capacity = len(data_list) * 2 + 3* 32,\n",
    "#                                  min_after_dequeue = len(data_list) *2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_batch(data_list):\n",
    "#     labels,paths = [],[]\n",
    "#     for data in data_list:\n",
    "#         labels.append(data[0])\n",
    "#         paths.append(data[1])\n",
    "#     queue = tf.train.slice_input_producer([labels,paths])\n",
    "#     label = queue[0]\n",
    "#     jpeg = tf.read_file(queue[1])\n",
    "#     image = tf.image.decode_jpeg(jpeg,channels=3)\n",
    "#     image = tf.image.resize_images(image,[256,256])\n",
    "\n",
    "#     image = tf.image.per_image_standardization(image)\n",
    "\n",
    "#     return tf.train.batch([image,label],len(data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(logits,labels):\n",
    "    correct_prediction = tf.equal(tf.argmax(logits,1),tf.argmax(labels,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,\"float\"))\n",
    "    return accuracy\n",
    "def split_image_and_label(data_list,LESS=False):\n",
    "    '''\n",
    "    data_list should be [[data,label]...]\n",
    "    '''\n",
    "    data = []\n",
    "    labels = []\n",
    "    if LESS:\n",
    "        i=0\n",
    "        for value,label in data_list:\n",
    "            i+=1\n",
    "            data.append(value)\n",
    "            labels.append(label)\n",
    "            if i == 1000:\n",
    "                break\n",
    "        return data,labels\n",
    "    else:\n",
    "        for value,label in data_list:\n",
    "            data.append(value)\n",
    "            labels.append(label)\n",
    "        return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 以下のセルにあるtrain, testは実データなので、読み込みが必要。\n",
    "# def convert_image_path_to_data(path):\n",
    "#     jpeg_r = tf.read_file(path)\n",
    "#     image = tf.image.decode_jpeg(jpeg_r,channels=3)\n",
    "#     image = tf.image.resize_images(image,[256,256])\n",
    "#     image = tf.image.per_image_standardization(image)\n",
    "\n",
    "#     return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opnecvによる読み込み\n",
    "import cv2 \n",
    "def convert_image_path_to_data_cv2(path,i):\n",
    "    try:\n",
    "#         img2 = cv2.imread(path,0) # 白黒画像で読み込み\n",
    "        img2 = cv2.imread(path)\n",
    "\n",
    "        img2 = cv2.resize(img2,dsize=(IMAGE_SIZE,IMAGE_SIZE),interpolation = cv2.INTER_CUBIC)\n",
    "        np_image_data = np.asarray(img2)\n",
    "        np_final = np.expand_dims(np_image_data,axis=0)\n",
    "        np_final = flatten(np_final)\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "        #1000 images / 15s\n",
    "        return np_final\n",
    "    except:\n",
    "        print(path)\n",
    "        print(i)\n",
    "        return np.zeros([256,256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(image):\n",
    "    image = image.flatten().astype(np.float32)/255.0\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/model/model.ckpt'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(sess, \"../data/model/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9063\n",
      "756\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "0\n",
      "success converting\n",
      "step 0, training accuracy 0.454154\n",
      "step 1, training accuracy 0.454154\n",
      "step 2, training accuracy 0.453823\n",
      "step 3, training accuracy 0.453823\n",
      "step 4, training accuracy 0.453492\n",
      "step 5, training accuracy 0.453161\n",
      "step 6, training accuracy 0.453161\n",
      "step 7, training accuracy 0.453161\n",
      "step 8, training accuracy 0.453161\n",
      "step 9, training accuracy 0.453161\n",
      "step 10, training accuracy 0.45283\n",
      "step 11, training accuracy 0.45283\n",
      "step 12, training accuracy 0.45283\n",
      "step 13, training accuracy 0.45283\n",
      "step 14, training accuracy 0.45283\n",
      "step 15, training accuracy 0.45283\n",
      "step 16, training accuracy 0.45283\n",
      "step 17, training accuracy 0.45283\n",
      "step 18, training accuracy 0.45283\n",
      "step 19, training accuracy 0.45283\n",
      "step 20, training accuracy 0.45283\n",
      "step 21, training accuracy 0.45283\n",
      "step 22, training accuracy 0.45283\n",
      "step 23, training accuracy 0.45283\n",
      "step 24, training accuracy 0.45283\n",
      "step 25, training accuracy 0.45283\n",
      "step 26, training accuracy 0.452499\n",
      "step 27, training accuracy 0.452499\n",
      "step 28, training accuracy 0.452499\n",
      "step 29, training accuracy 0.452499\n",
      "step 30, training accuracy 0.452499\n",
      "step 31, training accuracy 0.452499\n",
      "step 32, training accuracy 0.452499\n",
      "step 33, training accuracy 0.452499\n",
      "step 34, training accuracy 0.452168\n",
      "step 35, training accuracy 0.452168\n",
      "step 36, training accuracy 0.452168\n",
      "step 37, training accuracy 0.452168\n",
      "step 38, training accuracy 0.452168\n",
      "step 39, training accuracy 0.452168\n",
      "step 40, training accuracy 0.451506\n",
      "step 41, training accuracy 0.451506\n",
      "step 42, training accuracy 0.451506\n",
      "step 43, training accuracy 0.451175\n",
      "step 44, training accuracy 0.451175\n",
      "step 45, training accuracy 0.451506\n",
      "step 46, training accuracy 0.451175\n",
      "step 47, training accuracy 0.451175\n",
      "step 48, training accuracy 0.451175\n",
      "step 49, training accuracy 0.451175\n",
      "step 50, training accuracy 0.451506\n",
      "step 51, training accuracy 0.451837\n",
      "step 52, training accuracy 0.451837\n",
      "step 53, training accuracy 0.451506\n",
      "step 54, training accuracy 0.451506\n",
      "step 55, training accuracy 0.451175\n",
      "step 56, training accuracy 0.451506\n",
      "step 57, training accuracy 0.451506\n",
      "step 58, training accuracy 0.451506\n",
      "step 59, training accuracy 0.450513\n",
      "step 60, training accuracy 0.450844\n",
      "step 61, training accuracy 0.450844\n",
      "step 62, training accuracy 0.450513\n",
      "step 63, training accuracy 0.450513\n",
      "step 64, training accuracy 0.449851\n",
      "step 65, training accuracy 0.449851\n",
      "step 66, training accuracy 0.449851\n",
      "step 67, training accuracy 0.450182\n",
      "step 68, training accuracy 0.44952\n",
      "step 69, training accuracy 0.449189\n",
      "step 70, training accuracy 0.448858\n",
      "step 71, training accuracy 0.448196\n",
      "step 72, training accuracy 0.448196\n",
      "step 73, training accuracy 0.448196\n",
      "step 74, training accuracy 0.447534\n",
      "step 75, training accuracy 0.446872\n",
      "step 76, training accuracy 0.447534\n",
      "step 77, training accuracy 0.447865\n",
      "step 78, training accuracy 0.447865\n",
      "step 79, training accuracy 0.446541\n",
      "step 80, training accuracy 0.445879\n",
      "step 81, training accuracy 0.445548\n",
      "step 82, training accuracy 0.445217\n",
      "step 83, training accuracy 0.445217\n",
      "step 84, training accuracy 0.445217\n",
      "step 85, training accuracy 0.445548\n",
      "step 86, training accuracy 0.444886\n",
      "step 87, training accuracy 0.445217\n",
      "step 88, training accuracy 0.445548\n",
      "step 89, training accuracy 0.44621\n",
      "step 90, training accuracy 0.445548\n",
      "step 91, training accuracy 0.445217\n",
      "step 92, training accuracy 0.444224\n",
      "step 93, training accuracy 0.444555\n",
      "step 94, training accuracy 0.443893\n",
      "step 95, training accuracy 0.443893\n",
      "step 96, training accuracy 0.4429\n",
      "step 97, training accuracy 0.442238\n",
      "step 98, training accuracy 0.441576\n",
      "step 99, training accuracy 0.441907\n",
      "step 100, training accuracy 0.441576\n",
      "step 101, training accuracy 0.442238\n",
      "step 102, training accuracy 0.441907\n",
      "step 103, training accuracy 0.441907\n",
      "step 104, training accuracy 0.443562\n",
      "step 105, training accuracy 0.442569\n",
      "step 106, training accuracy 0.4429\n",
      "step 107, training accuracy 0.4429\n",
      "step 108, training accuracy 0.442238\n",
      "step 109, training accuracy 0.442238\n",
      "step 110, training accuracy 0.442238\n",
      "step 111, training accuracy 0.442238\n",
      "step 112, training accuracy 0.442238\n",
      "step 113, training accuracy 0.441245\n",
      "step 114, training accuracy 0.441576\n",
      "step 115, training accuracy 0.442238\n",
      "step 116, training accuracy 0.441907\n",
      "step 117, training accuracy 0.441907\n",
      "step 118, training accuracy 0.442238\n",
      "step 119, training accuracy 0.4429\n",
      "test accuracy 0.452381\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Parent directory of model.ckpt doesn't exist, can't save.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/yes/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: ; No such file or directory\n\t [[{{node save/SaveV2}} = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, conv1/Variable, conv1/Variable/Adadelta, conv1/Variable/Adadelta_1, conv1/Variable_1, conv1/Variable_1/Adadelta, conv1/Variable_1/Adadelta_1, conv2/Variable, conv2/Variable/Adadelta, conv2/Variable/Adadelta_1, conv2/Variable_1, conv2/Variable_1/Adadelta, conv2/Variable_1/Adadelta_1, zenketsu1/Variable, zenketsu1/Variable/Adadelta, zenketsu1/Variable/Adadelta_1, zenketsu1/Variable_1, zenketsu1/Variable_1/Adadelta, zenketsu1/Variable_1/Adadelta_1, zenketsu2/Variable, zenketsu2/Variable/Adadelta, zenketsu2/Variable/Adadelta_1, zenketsu2/Variable_1, zenketsu2/Variable_1/Adadelta, zenketsu2/Variable_1/Adadelta_1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/yes/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs)\u001b[0m\n\u001b[1;32m   1440\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m               {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[1;32m   1442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: ; No such file or directory\n\t [[node save/SaveV2 (defined at <ipython-input-40-8983cb0653c4>:24)  = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, conv1/Variable, conv1/Variable/Adadelta, conv1/Variable/Adadelta_1, conv1/Variable_1, conv1/Variable_1/Adadelta, conv1/Variable_1/Adadelta_1, conv2/Variable, conv2/Variable/Adadelta, conv2/Variable/Adadelta_1, conv2/Variable_1, conv2/Variable_1/Adadelta, conv2/Variable_1/Adadelta_1, zenketsu1/Variable, zenketsu1/Variable/Adadelta, zenketsu1/Variable/Adadelta_1, zenketsu1/Variable_1, zenketsu1/Variable_1/Adadelta, zenketsu1/Variable_1/Adadelta_1, zenketsu2/Variable, zenketsu2/Variable/Adadelta, zenketsu2/Variable/Adadelta_1, zenketsu2/Variable_1, zenketsu2/Variable_1/Adadelta, zenketsu2/Variable_1/Adadelta_1)]]\n\nCaused by op 'save/SaveV2', defined at:\n  File \"/home/genki/yes/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/genki/yes/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/genki/yes/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/genki/yes/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/genki/yes/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/genki/yes/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/genki/yes/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/genki/yes/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"/home/genki/yes/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/genki/yes/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/genki/yes/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/genki/yes/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/genki/yes/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/genki/yes/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/genki/yes/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/genki/yes/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/genki/yes/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/genki/yes/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/genki/yes/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/genki/yes/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/genki/yes/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/genki/yes/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/genki/yes/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/home/genki/yes/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/genki/yes/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/genki/yes/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/genki/yes/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-40-8983cb0653c4>\", line 24, in <module>\n    saver = tf.train.Saver()\n  File \"/home/genki/yes/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1102, in __init__\n    self.build()\n  File \"/home/genki/yes/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1114, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/genki/yes/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1151, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/genki/yes/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 792, in _build_internal\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\n  File \"/home/genki/yes/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 284, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"/home/genki/yes/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 202, in save_op\n    tensors)\n  File \"/home/genki/yes/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1690, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"/home/genki/yes/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/genki/yes/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/genki/yes/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/genki/yes/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): ; No such file or directory\n\t [[node save/SaveV2 (defined at <ipython-input-40-8983cb0653c4>:24)  = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, conv1/Variable, conv1/Variable/Adadelta, conv1/Variable/Adadelta_1, conv1/Variable_1, conv1/Variable_1/Adadelta, conv1/Variable_1/Adadelta_1, conv2/Variable, conv2/Variable/Adadelta, conv2/Variable/Adadelta_1, conv2/Variable_1, conv2/Variable_1/Adadelta, conv2/Variable_1/Adadelta_1, zenketsu1/Variable, zenketsu1/Variable/Adadelta, zenketsu1/Variable/Adadelta_1, zenketsu1/Variable_1, zenketsu1/Variable_1/Adadelta, zenketsu1/Variable_1/Adadelta_1, zenketsu2/Variable, zenketsu2/Variable/Adadelta, zenketsu2/Variable/Adadelta_1, zenketsu2/Variable_1, zenketsu2/Variable_1/Adadelta, zenketsu2/Variable_1/Adadelta_1)]]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-8983cb0653c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# 最終的なモデルを保存\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/yes/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m               \"Parent directory of {} doesn't exist, can't save.\".format(\n\u001b[1;32m   1457\u001b[0m                   save_path))\n\u001b[0;32m-> 1458\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrite_meta_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Parent directory of model.ckpt doesn't exist, can't save."
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    images_placeholder = tf.placeholder(\"float\",shape=(None,IMAGE_PIXELS))\n",
    "    labels_placeholder = tf.placeholder(\"float\",shape=(None,NUM_CLASSES))\n",
    "    keep_prob = tf.placeholder(\"float\")\n",
    "    \n",
    "    logits = inference(images_placeholder,keep_prob)\n",
    "    loss_value = loss(logits,labels_placeholder)\n",
    "    train_op = training(loss_value,learning_rate)\n",
    "    acc = accuracy(logits,labels_placeholder)\n",
    "\n",
    "    #for debugging True\n",
    "    train_image, train_label = split_image_and_label(train,False)\n",
    "    test_image,test_label = split_image_and_label(test,False) \n",
    "    print(len(train_image))\n",
    "    print(len(test_image))\n",
    "    \n",
    "    train_image = [convert_image_path_to_data_cv2(path,i) for i,path in enumerate(train_image)]\n",
    "    test_image = [convert_image_path_to_data_cv2(path,i) for i,path in enumerate(test_image)]\n",
    "    #takes 20 mins\n",
    "    print(\"success converting\")\n",
    "    \n",
    "    \n",
    "    # 保存の準備\n",
    "    saver = tf.train.Saver()\n",
    "    # Sessionの作成\n",
    "    sess = tf.Session()\n",
    "    # 変数の初期化\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    # TensorBoardで表示する値の設定\n",
    "#     summary_op = tf.merge_all_summaries()\n",
    "#     summary_writer = tf.train.SummaryWriter(FLAGS.train_dir, sess.graph_def)\n",
    "\n",
    "    # 訓練の実行\n",
    "    for step in range(max_steps):\n",
    "        for i in range(int(len(train_image)/BATCH_SIZE)):\n",
    "            # batch_size分の画像に対して訓練の実行\n",
    "            batch = BATCH_SIZE*i\n",
    "            # feed_dictでplaceholderに入れるデータを指定する\n",
    "            sess.run(train_op, feed_dict={\n",
    "              images_placeholder: train_image[batch:batch+BATCH_SIZE],\n",
    "              labels_placeholder: train_label[batch:batch+BATCH_SIZE],\n",
    "              keep_prob: 0.5})\n",
    "\n",
    "        # 1 step終わるたびに精度を計算する\n",
    "        train_accuracy = sess.run(acc, feed_dict={\n",
    "            images_placeholder: train_image,\n",
    "            labels_placeholder: train_label,\n",
    "            keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(step, train_accuracy))\n",
    "\n",
    "#         # 1 step終わるたびにTensorBoardに表示する値を追加する\n",
    "#         summary_str = sess.run(summary_op, feed_dict={\n",
    "#             images_placeholder: train_image,\n",
    "#             labels_placeholder: train_label,\n",
    "#             keep_prob: 1.0})\n",
    "#         summary_writer.add_summary(summary_str, step)\n",
    "\n",
    "# 訓練が終了したらテストデータに対する精度を表示\n",
    "print(\"test accuracy %g\"%sess.run(acc, feed_dict={\n",
    "    images_placeholder: test_image,\n",
    "    labels_placeholder: test_label,\n",
    "    keep_prob: 1.0}))\n",
    "\n",
    "# 最終的なモデルを保存\n",
    "save_path = saver.save(sess, \"../data/model/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 編集用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
